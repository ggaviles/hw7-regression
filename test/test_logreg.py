"""
Write your unit tests here. Some tests to include are listed below.
This is not an exhaustive list.

- check that prediction is working correctly
- check that your loss function is being calculated correctly
- check that your gradient is being calculated correctly
- check that your weights update during training
"""

# Imports
import pytest
import sklearn.linear_model

import regression.utils
import regression.logreg
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

def test_prediction():
	X, y = regression.utils.loadDataset()  # Read in dataset X and labels y
	X_train, X_test, y_train, y_test = regression.utils.loadDataset(split_seed=16, split_percent=0.8)

	# Chose l2 penalty because also used L2 regularization in my implemented Logistic Regressor
	# Chose C to be 2 and my reg_param to be 0.5 because C is the inverse of the regularization parameter
	sklearn_model = LogisticRegression(penalty='l2', C=2)
	sklearn_model.fit(X_train, y_train)
	sklearn_pred_labels = sklearn_model.predict(X_test)

	model = regression.logreg.LogisticRegressor(num_feats=X.shape[1], learning_rate=0.001, max_iter=1000,
												batch_size=5, reg_param=0.5)
	model.train_model(X_train, y_train, X_test, y_test)
	pred_labels = model.make_prediction(X_test)
	# print(f"Learned parameters: w = {model.W}")

	# Calculate the mean error between the matrix of labels generated by sklearn and the matrix of labels generated
	# by my LogisticRegressor
	error = np.mean(sklearn_pred_labels != pred_labels)

	# Check that the mean error between sklearn label prediction and my LogisticRegressor prediction is less than 50%
	assert error*100 < 50

def test_loss_function():
	pass

def test_gradient():
	X, y = regression.utils.loadDataset()
	X_train, X_test, y_train, y_test = regression.utils.loadDataset(split_seed=16, split_percent=0.8)
	sklearn_model = LogisticRegression(penalty='l2', C=4.0)
	sklearn_model.fit(X_train, y_train)
	sklearn_pred_labels = sklearn_model.predict(X_test)

	model = regression.logreg.LogisticRegressor(num_feats=X.shape[1], learning_rate=0.001, max_iter=10000, batch_size=10, reg_param=0.25)
	model.train_model(X_train, y_train, X_test, y_test)
	pred_labels = model.make_prediction(X_test)

	error = np.mean(sklearn_pred_labels != pred_labels)
	print(error*100)



def test_training():
	X, y = regression.utils.loadDataset()
	X_train, X_test, y_train, y_test = regression.utils.loadDataset(split_seed=16, split_percent=0.8)
	sklearn_model = LogisticRegression(penalty='l2', C=4.0)
	sklearn_model.fit(X_train, y_train)
	sklearn_pred_labels = sklearn_model.predict(X_test)
	print(sklearn_pred_labels)

	model = regression.logreg.LogisticRegressor(num_feats=X.shape[1], learning_rate=0.001, max_iter=10000,
												batch_size=10, reg_param=0.25)
	model.train_model(X_train, y_train, X_test, y_test)
	pred_labels = model.make_prediction(X_test)
	print(pred_labels)
	# print(f"Learned parameters: w = {model.W}")

	error = np.mean(sklearn_pred_labels != pred_labels)
	print(error * 100)

